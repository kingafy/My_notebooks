{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Selecting dimensionality reduction with Pipeline and GridSearchCV\n",
    "\n",
    "\n",
    "This example constructs a pipeline that does dimensionality\n",
    "reduction followed by prediction with a support vector\n",
    "classifier. It demonstrates the use of GridSearchCV and\n",
    "Pipeline to optimize over different classes of estimators in a\n",
    "single CV run -- unsupervised PCA and NMF dimensionality\n",
    "reductions are compared to univariate feature selection during\n",
    "the grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('feature_selection',\n",
       "  SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          norm_order=1, prefit=False, threshold=None)),\n",
       " ('classify',\n",
       "  LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0))]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "print(__doc__)\n",
    "\n",
    "##categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "'''\n",
    "pipe = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\",dual=False))),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', LinearSVC())\n",
    "])\n",
    "'''\n",
    "pipe = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(ExtraTreesClassifier())),\n",
    "    ('classify', LinearSVC())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_FEATURES_OPTIONS = [2, 4, 8]\n",
    "N_FEATURES_chi = [10, 20, 30]\n",
    "C_OPTIONS = [1, 10, 100, 1000]\n",
    "NUMBER_OF_ESTIMATORS_RF = [50, 80, 100]\n",
    "##penalty param\n",
    "L1_C1 = [0.01, 0.02, 0.05]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##the below code is working..Remeber __ is imp instead of _ for parameters\n",
    "'''\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectPercentile(chi2)],\n",
    "        'reduce_dim__percentile': N_FEATURES_chi\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectPercentile(chi2)],\n",
    "        'reduce_dim__percentile': N_FEATURES_chi\n",
    "    }\n",
    "    ]\n",
    "\n",
    "'''\n",
    "'''\n",
    "##BELOW CODEBEST SO FAR\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectPercentile(chi2)],\n",
    "        'reduce_dim__percentile': N_FEATURES_chi\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [PCA(), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectFromModel(LinearSVC(penalty=\"l1\",dual=False))]\n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectFromModel(ExtraTreesClassifier(n_estimators=50))]\n",
    "\n",
    "    }\n",
    "    \n",
    "]\n",
    "'''\n",
    "\n",
    "##my experiment(included chi2/ensemble tree classifier/mutual_info_classif(f_classif),L1based feature selection(Linear SVC))\n",
    "param_grid = [\n",
    "  \n",
    "      {\n",
    "        'feature_selection': [SelectKBest(chi2)],\n",
    "        'feature_selection__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectPercentile(chi2)],\n",
    "        'feature_selection__percentile': N_FEATURES_chi\n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectFromModel(ExtraTreesClassifier())],\n",
    "        'feature_selection__estimator__n_estimators' : NUMBER_OF_ESTIMATORS_RF\n",
    "                             \n",
    "    },\n",
    "    {   'feature_selection': [SelectPercentile(f_classif)],\n",
    "        'feature_selection__percentile': N_FEATURES_chi\n",
    "           \n",
    "    },\n",
    "    {\n",
    "        'feature_selection': [SelectFromModel(LinearSVC(penalty=\"l1\",dual=False, C =0.01))],\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "''' \n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "###reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "reducer_labels = ['KBest(chi2)', 'SelectPercentile', 'featureselection' ]\n",
    "\n",
    "pipe.steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'feature_selection', 'classify', 'feature_selection__estimator__bootstrap', 'feature_selection__estimator__class_weight', 'feature_selection__estimator__criterion', 'feature_selection__estimator__max_depth', 'feature_selection__estimator__max_features', 'feature_selection__estimator__max_leaf_nodes', 'feature_selection__estimator__min_impurity_decrease', 'feature_selection__estimator__min_impurity_split', 'feature_selection__estimator__min_samples_leaf', 'feature_selection__estimator__min_samples_split', 'feature_selection__estimator__min_weight_fraction_leaf', 'feature_selection__estimator__n_estimators', 'feature_selection__estimator__n_jobs', 'feature_selection__estimator__oob_score', 'feature_selection__estimator__random_state', 'feature_selection__estimator__verbose', 'feature_selection__estimator__warm_start', 'feature_selection__estimator', 'feature_selection__norm_order', 'feature_selection__prefit', 'feature_selection__threshold', 'classify__C', 'classify__class_weight', 'classify__dual', 'classify__fit_intercept', 'classify__intercept_scaling', 'classify__loss', 'classify__max_iter', 'classify__multi_class', 'classify__penalty', 'classify__random_state', 'classify__tol', 'classify__verbose'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_sam...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid=[{'feature_selection': [SelectKBest(k=10, score_func=<function chi2 at 0x000002D16FEF3EA0>)], 'feature_selection__k': [2, 4, 8], 'classify__C': [1, 10, 100, 1000]}, {'feature_selection': [SelectPercentile(percentile=10,\n",
       "         score_func=<function chi2 at 0x000002D16FEF3EA0>)], 'feature...ndom_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "        norm_order=1, prefit=False, threshold=None)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, cv=2, n_jobs=2, param_grid=param_grid)\n",
    "digits = load_digits()\n",
    "grid.fit(digits.data, digits.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "SelectFromModel(estimator=LinearSVC(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=False, threshold=None)\n"
     ]
    }
   ],
   "source": [
    "model1 = grid.best_estimator_\n",
    "#print(model1.named_steps['reduce_dim'])\n",
    "print(model1.named_steps['classify'])\n",
    "print(model1.named_steps['feature_selection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_selection': SelectFromModel(estimator=LinearSVC(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       "         norm_order=1, prefit=False, threshold=None)}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Digit classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
